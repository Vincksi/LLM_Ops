from typing import Dict, List, Optional, Union, Any
from pydantic import BaseModel, Field, validator
from datetime import datetime
from enum import Enum
from .constants import ModelCapability, ProviderType

# Common Models

class Message(BaseModel):
    """Represents a message in a chat conversation."""
    role: str = Field(..., description="The role of the author of this message.")
    content: str = Field(..., description="The content of the message.")
    name: Optional[str] = Field(None, description="The name of the author of this message.")

class Usage(BaseModel):
    """Token usage information."""
    prompt_tokens: int = Field(0, description="Number of tokens in the prompt.")
    completion_tokens: int = Field(0, description="Number of tokens in the completion.")
    total_tokens: int = Field(0, description="Total number of tokens used.")

class ModelInfo(BaseModel):
    """Information about an LLM model."""
    id: str = Field(..., description="The model identifier.")
    name: str = Field(..., description="The human-readable name of the model.")
    provider: str = Field(..., description="The provider of this model.")
    capabilities: List[str] = Field(..., description="The capabilities of this model.")
    max_tokens: int = Field(..., description="The maximum number of tokens the model can process.")
    description: Optional[str] = Field(None, description="A description of the model.")
    context_window: Optional[int] = Field(None, description="The maximum context window size.")
    
# Request Models

class ChatCompletionRequest(BaseModel):
    """Request model for chat completions."""
    model: str = Field(..., description="The model to use for completion.")
    messages: List[Message] = Field(..., description="A list of messages in the conversation.")
    provider: Optional[str] = Field(None, description="The provider to use. If not specified, the default provider will be used.")
    temperature: Optional[float] = Field(0.7, description="Sampling temperature to use.")
    top_p: Optional[float] = Field(1.0, description="Nucleus sampling parameter.")
    max_tokens: Optional[int] = Field(None, description="Maximum number of tokens to generate.")
    stream: Optional[bool] = Field(False, description="Whether to stream the response.")
    stop: Optional[Union[str, List[str]]] = Field(None, description="Sequences where the API will stop generating further tokens.")
    
    @validator('temperature')
    def temperature_must_be_valid(cls, v):
        if v is not None and (v < 0 or v > 2):
            raise ValueError('temperature must be between 0 and 2')
        return v
    
    @validator('top_p')
    def top_p_must_be_valid(cls, v):
        if v is not None and (v <= 0 or v > 1):
            raise ValueError('top_p must be between 0 and 1')
        return v

class EmbeddingRequest(BaseModel):
    """Request model for embeddings."""
    model: str = Field(..., description="The model to use for embeddings.")
    input: Union[str, List[str]] = Field(..., description="The input text to embed.")
    provider: Optional[str] = Field(None, description="The provider to use. If not specified, the default provider will be used.")

# Response Models

class ChatCompletionChoice(BaseModel):
    """A completion choice returned by the API."""
    index: int = Field(..., description="The index of this choice.")
    message: Message = Field(..., description="The message generated by the model.")
    finish_reason: Optional[str] = Field(None, description="The reason why the model stopped generating.")

class ChatCompletionResponse(BaseModel):
    """Response model for chat completions."""
    id: str = Field(..., description="The unique identifier for this completion.")
    object: str = Field("chat.completion", description="The object type.")
    created: int = Field(..., description="The Unix timestamp of when the completion was created.")
    model: str = Field(..., description="The model used for completion.")
    provider: str = Field(..., description="The provider used for completion.")
    choices: List[ChatCompletionChoice] = Field(..., description="The completion choices.")
    usage: Usage = Field(..., description="The token usage for this request.")

class EmbeddingData(BaseModel):
    """Embedding data for a single input."""
    index: int = Field(..., description="The index of this embedding.")
    embedding: List[float] = Field(..., description="The embedding vector.")
    object: str = Field("embedding", description="The object type.")

class EmbeddingResponse(BaseModel):
    """Response model for embeddings."""
    object: str = Field("list", description="The object type.")
    data: List[EmbeddingData] = Field(..., description="The embedding data.")
    model: str = Field(..., description="The model used for embeddings.")
    provider: str = Field(..., description="The provider used for embeddings.")
    usage: Usage = Field(..., description="The token usage for this request.")

class ModelListResponse(BaseModel):
    """Response model for listing available models."""
    object: str = Field("list", description="The object type.")
    data: List[ModelInfo] = Field(..., description="The list of available models.")

# Error Models

class ErrorDetail(BaseModel):
    """Details about an error."""
    code: str = Field(..., description="Error code.")
    message: str = Field(..., description="Error message.")
    details: Optional[Dict[str, Any]] = Field(None, description="Additional error details.")

class ErrorResponse(BaseModel):
    """Error response model."""
    error: ErrorDetail = Field(..., description="Error details.") 